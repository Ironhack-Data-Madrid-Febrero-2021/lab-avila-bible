{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Avila Bible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will explore the [**Avila Bible dataset**](https://archive.ics.uci.edu/ml/datasets/Avila) which has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible. The prediction task consists in associating each pattern to a copyist. You will use supervised learning algorithms to figure out what feature patterns each copyist are likely to have and use our model to predict those copyist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before your start:\n",
    "    - Comment as much as you can and use the APIla-bible in the README.md,\n",
    "    - Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando librerías\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![machine-learning](https://miro.medium.com/proxy/1*halC1X4ydv_3yHYxKqvrwg.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avila data set has been extracted from 800 images of the the **Avila Bible**, a giant Latin copy of the whole Bible produced during the XII century between Italy and Spain. The palaeographic analysis of the  manuscript has  individuated the presence of 8 copyists. The pages written by each copyist are not equally numerous. \n",
    "Each pattern contains 10 features and corresponds to a group of 4 consecutive rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What am I expected to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, your prediction task consists in associating each pattern to one of the 8 monks we will be evaluating (labeled as:  Marcus, Clarius, Philippus, Coronavirucus, Mongucus, Paithonius, Ubuntius, Esequlius). For that aim, you should: \n",
    "- Train a minimum of 4 different models\n",
    "- Must contain a summary of the machine learning tools and algorithms\n",
    "- and the results or the score obtained with each of them\n",
    "\n",
    "You won't get much more instructions from now on. Remember to comment your code as much as you can. Keep the requirements in mind and have fun! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/training_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.241386</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>-0.127126</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.314889</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.316412</td>\n",
       "      <td>0.188810</td>\n",
       "      <td>0.134922</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.352558</td>\n",
       "      <td>0.082701</td>\n",
       "      <td>0.703981</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.391033</td>\n",
       "      <td>0.408929</td>\n",
       "      <td>1.045014</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>-0.448209</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.281897</td>\n",
       "      <td>0.175168</td>\n",
       "      <td>-0.152490</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.889332</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-0.024328</td>\n",
       "      <td>0.905984</td>\n",
       "      <td>-0.877830</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.326430</td>\n",
       "      <td>-0.652394</td>\n",
       "      <td>0.384996</td>\n",
       "      <td>-1.694222</td>\n",
       "      <td>-0.185173</td>\n",
       "      <td>-1.138481</td>\n",
       "      <td>-0.232828</td>\n",
       "      <td>-1.747116</td>\n",
       "      <td>-1.183175</td>\n",
       "      <td>-0.807380</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.437525</td>\n",
       "      <td>-0.471816</td>\n",
       "      <td>0.463236</td>\n",
       "      <td>-0.545248</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.972381</td>\n",
       "      <td>0.824183</td>\n",
       "      <td>-3.108388</td>\n",
       "      <td>-2.991700</td>\n",
       "      <td>-1.141030</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.412837</td>\n",
       "      <td>-0.346197</td>\n",
       "      <td>0.601936</td>\n",
       "      <td>2.211191</td>\n",
       "      <td>0.440474</td>\n",
       "      <td>0.356414</td>\n",
       "      <td>-1.138838</td>\n",
       "      <td>1.623671</td>\n",
       "      <td>2.371513</td>\n",
       "      <td>1.346221</td>\n",
       "      <td>Mongucus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056229</td>\n",
       "      <td>0.187683</td>\n",
       "      <td>-0.031104</td>\n",
       "      <td>-0.958476</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.598658</td>\n",
       "      <td>0.861934</td>\n",
       "      <td>-0.885246</td>\n",
       "      <td>-0.528364</td>\n",
       "      <td>-0.848946</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-0.128929</td>\n",
       "      <td>-0.032150</td>\n",
       "      <td>0.068476</td>\n",
       "      <td>-0.151655</td>\n",
       "      <td>-0.989576</td>\n",
       "      <td>-0.806282</td>\n",
       "      <td>0.295677</td>\n",
       "      <td>0.259758</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>-0.767984</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.130292</td>\n",
       "      <td>-0.275537</td>\n",
       "      <td>0.274747</td>\n",
       "      <td>-0.574878</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>2.889429</td>\n",
       "      <td>0.635431</td>\n",
       "      <td>-1.180749</td>\n",
       "      <td>-0.840179</td>\n",
       "      <td>2.303929</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080916</td>\n",
       "      <td>0.438921</td>\n",
       "      <td>0.143160</td>\n",
       "      <td>-0.523288</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.598658</td>\n",
       "      <td>0.106925</td>\n",
       "      <td>-0.641641</td>\n",
       "      <td>0.188810</td>\n",
       "      <td>-0.491704</td>\n",
       "      <td>Ubuntius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-0.474557</td>\n",
       "      <td>0.446772</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.716161</td>\n",
       "      <td>0.351096</td>\n",
       "      <td>2.723330</td>\n",
       "      <td>1.692443</td>\n",
       "      <td>-1.912981</td>\n",
       "      <td>-1.588534</td>\n",
       "      <td>1.500599</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.241386</td>\n",
       "      <td>-0.157769</td>\n",
       "      <td>0.338762</td>\n",
       "      <td>-1.203923</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.058835</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>1.066119</td>\n",
       "      <td>0.344717</td>\n",
       "      <td>-0.035550</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>-0.042522</td>\n",
       "      <td>-0.299090</td>\n",
       "      <td>0.182281</td>\n",
       "      <td>1.151314</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>2.100457</td>\n",
       "      <td>0.446679</td>\n",
       "      <td>-0.757551</td>\n",
       "      <td>-0.621908</td>\n",
       "      <td>1.734710</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.117948</td>\n",
       "      <td>0.627349</td>\n",
       "      <td>0.075589</td>\n",
       "      <td>0.831628</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>1.602159</td>\n",
       "      <td>2.409701</td>\n",
       "      <td>-0.742718</td>\n",
       "      <td>-0.497183</td>\n",
       "      <td>0.196511</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>-0.042522</td>\n",
       "      <td>0.187683</td>\n",
       "      <td>0.224957</td>\n",
       "      <td>0.290963</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.017310</td>\n",
       "      <td>0.333428</td>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.126447</td>\n",
       "      <td>-0.077694</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.117948</td>\n",
       "      <td>-0.189174</td>\n",
       "      <td>0.029355</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.887365</td>\n",
       "      <td>-1.304580</td>\n",
       "      <td>0.295677</td>\n",
       "      <td>1.811476</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>-1.212661</td>\n",
       "      <td>Coronavirucus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.377169</td>\n",
       "      <td>-0.079257</td>\n",
       "      <td>0.153829</td>\n",
       "      <td>-1.102952</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.266459</td>\n",
       "      <td>0.031425</td>\n",
       "      <td>1.179388</td>\n",
       "      <td>-0.060642</td>\n",
       "      <td>-0.139983</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>-0.042522</td>\n",
       "      <td>-0.416858</td>\n",
       "      <td>0.569929</td>\n",
       "      <td>-2.224653</td>\n",
       "      <td>0.082961</td>\n",
       "      <td>3.346203</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>-1.205406</td>\n",
       "      <td>-1.837986</td>\n",
       "      <td>3.057808</td>\n",
       "      <td>Esequlius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>-0.091897</td>\n",
       "      <td>-0.118513</td>\n",
       "      <td>0.189393</td>\n",
       "      <td>1.280303</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.564038</td>\n",
       "      <td>0.597681</td>\n",
       "      <td>0.536330</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.297376</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.105604</td>\n",
       "      <td>-0.149918</td>\n",
       "      <td>0.438342</td>\n",
       "      <td>0.934659</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-1.324733</td>\n",
       "      <td>-1.931530</td>\n",
       "      <td>-0.011066</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.241386  0.109171 -0.127126  0.380626  0.172340  0.314889  0.484429   \n",
       "1   0.303106  0.352558  0.082701  0.703981  0.261718 -0.391033  0.408929   \n",
       "2  -0.116585  0.281897  0.175168 -0.152490  0.261718 -0.889332  0.371178   \n",
       "3  -0.326430 -0.652394  0.384996 -1.694222 -0.185173 -1.138481 -0.232828   \n",
       "4  -0.437525 -0.471816  0.463236 -0.545248  0.261718 -0.972381  0.824183   \n",
       "5  -0.412837 -0.346197  0.601936  2.211191  0.440474  0.356414 -1.138838   \n",
       "6   0.056229  0.187683 -0.031104 -0.958476  0.261718 -0.598658  0.861934   \n",
       "7  -0.128929 -0.032150  0.068476 -0.151655 -0.989576 -0.806282  0.295677   \n",
       "8   0.130292 -0.275537  0.274747 -0.574878  0.261718  2.889429  0.635431   \n",
       "9   0.080916  0.438921  0.143160 -0.523288  0.261718 -0.598658  0.106925   \n",
       "10 -0.474557  0.446772 -3.210528 -0.716161  0.351096  2.723330  1.692443   \n",
       "11  0.241386 -0.157769  0.338762 -1.203923  0.261718 -0.058835  0.182426   \n",
       "12 -0.042522 -0.299090  0.182281  1.151314  0.261718  2.100457  0.446679   \n",
       "13  0.117948  0.627349  0.075589  0.831628  0.261718  1.602159  2.409701   \n",
       "14 -0.042522  0.187683  0.224957  0.290963  0.261718 -0.017310  0.333428   \n",
       "15  0.117948 -0.189174  0.029355  0.763359  0.887365 -1.304580  0.295677   \n",
       "16  0.377169 -0.079257  0.153829 -1.102952  0.261718 -0.266459  0.031425   \n",
       "17 -0.042522 -0.416858  0.569929 -2.224653  0.082961  3.346203  0.182426   \n",
       "18 -0.091897 -0.118513  0.189393  1.280303  0.261718  0.564038  0.597681   \n",
       "19  0.105604 -0.149918  0.438342  0.934659  0.261718  0.065740  0.371178   \n",
       "\n",
       "           7         8         9             10  \n",
       "0   0.316412  0.188810  0.134922         Marcus  \n",
       "1   1.045014  0.282354 -0.448209        Clarius  \n",
       "2  -0.024328  0.905984 -0.877830      Philippus  \n",
       "3  -1.747116 -1.183175 -0.807380      Philippus  \n",
       "4  -3.108388 -2.991700 -1.141030      Philippus  \n",
       "5   1.623671  2.371513  1.346221       Mongucus  \n",
       "6  -0.885246 -0.528364 -0.848946        Clarius  \n",
       "7   0.259758  0.251173 -0.767984        Clarius  \n",
       "8  -1.180749 -0.840179  2.303929         Marcus  \n",
       "9  -0.641641  0.188810 -0.491704       Ubuntius  \n",
       "10 -1.912981 -1.588534  1.500599         Marcus  \n",
       "11  1.066119  0.344717 -0.035550         Marcus  \n",
       "12 -0.757551 -0.621908  1.734710         Marcus  \n",
       "13 -0.742718 -0.497183  0.196511         Marcus  \n",
       "14  0.030113  0.126447 -0.077694         Marcus  \n",
       "15  1.811476  0.251173 -1.212661  Coronavirucus  \n",
       "16  1.179388 -0.060642 -0.139983         Marcus  \n",
       "17 -1.205406 -1.837986  3.057808      Esequlius  \n",
       "18  0.536330  0.251173  0.297376         Marcus  \n",
       "19 -1.324733 -1.931530 -0.011066         Marcus  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keep calm and code on!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12017 entries, 0 to 12016\n",
      "Data columns (total 11 columns):\n",
      "0     12017 non-null float64\n",
      "1     12017 non-null float64\n",
      "2     12017 non-null float64\n",
      "3     12017 non-null float64\n",
      "4     12017 non-null float64\n",
      "5     12017 non-null float64\n",
      "6     12017 non-null float64\n",
      "7     12017 non-null float64\n",
      "8     12017 non-null float64\n",
      "9     12017 non-null float64\n",
      "10    12017 non-null object\n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable objetivo: \"10\"\n",
    "Representando a cada uno de los 8 monjes que la han escrito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualización de las categorías de la variable objetivo\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.countplot(y = data['10']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - train your models, make the best prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoder \n",
    "Encode target labels with value between 0 and n_classes-1.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "data[\"numeric\"] = le.fit_transform(data[\"10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.241386</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>-0.127126</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.314889</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.316412</td>\n",
       "      <td>0.188810</td>\n",
       "      <td>0.134922</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.352558</td>\n",
       "      <td>0.082701</td>\n",
       "      <td>0.703981</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.391033</td>\n",
       "      <td>0.408929</td>\n",
       "      <td>1.045014</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>-0.448209</td>\n",
       "      <td>Clarius</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.281897</td>\n",
       "      <td>0.175168</td>\n",
       "      <td>-0.152490</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.889332</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-0.024328</td>\n",
       "      <td>0.905984</td>\n",
       "      <td>-0.877830</td>\n",
       "      <td>Philippus</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.326430</td>\n",
       "      <td>-0.652394</td>\n",
       "      <td>0.384996</td>\n",
       "      <td>-1.694222</td>\n",
       "      <td>-0.185173</td>\n",
       "      <td>-1.138481</td>\n",
       "      <td>-0.232828</td>\n",
       "      <td>-1.747116</td>\n",
       "      <td>-1.183175</td>\n",
       "      <td>-0.807380</td>\n",
       "      <td>Philippus</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.437525</td>\n",
       "      <td>-0.471816</td>\n",
       "      <td>0.463236</td>\n",
       "      <td>-0.545248</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.972381</td>\n",
       "      <td>0.824183</td>\n",
       "      <td>-3.108388</td>\n",
       "      <td>-2.991700</td>\n",
       "      <td>-1.141030</td>\n",
       "      <td>Philippus</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.241386  0.109171 -0.127126  0.380626  0.172340  0.314889  0.484429   \n",
       "1  0.303106  0.352558  0.082701  0.703981  0.261718 -0.391033  0.408929   \n",
       "2 -0.116585  0.281897  0.175168 -0.152490  0.261718 -0.889332  0.371178   \n",
       "3 -0.326430 -0.652394  0.384996 -1.694222 -0.185173 -1.138481 -0.232828   \n",
       "4 -0.437525 -0.471816  0.463236 -0.545248  0.261718 -0.972381  0.824183   \n",
       "\n",
       "          7         8         9         10  numeric  \n",
       "0  0.316412  0.188810  0.134922     Marcus        3  \n",
       "1  1.045014  0.282354 -0.448209    Clarius        0  \n",
       "2 -0.024328  0.905984 -0.877830  Philippus        6  \n",
       "3 -1.747116 -1.183175 -0.807380  Philippus        6  \n",
       "4 -3.108388 -2.991700 -1.141030  Philippus        6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando una lista de todas las columnas que funcionan como variables dependientes (todas menos 10 y numeric)\n",
    "columnas = [a for a in data.columns if a not in [\"10\",\"numeric\"]]\n",
    "\n",
    "# Asignando valores a X e y\n",
    "X = data[columnas]\n",
    "y = data[\"numeric\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_Test Split\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividiendo el dataset en train y test para poder validar el modelo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape is: (9613, 10)\n",
      "y train shape is: (9613,)\n",
      "x test shape is: (2404, 10)\n",
      "y test shape is: (2404,)\n"
     ]
    }
   ],
   "source": [
    "print('x train shape is:', X_train.shape)\n",
    "print('y train shape is:', y_train.shape)\n",
    "print('x test shape is:', X_test.shape)\n",
    "print('y test shape is:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train One Model\n",
    "\n",
    "Classifier implementing the k-nearest neighbors vote. https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asignando y entrando el modelo K-Nearest neighbors\n",
    "neigh = KNeighborsClassifier(n_neighbors = 8)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 7, ..., 3, 0, 6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediciendo la variable objetivo\n",
    "y_pred = neigh.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quería guardar la y_pred en una columna del dataframe para hacer una crosstab, pero habría que entrenar el modelo con los datos enteros, ya que ahora la shape es distinta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring metrics for multi-class classification algorithms\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy\n",
    "- Precission\n",
    "- Recall\n",
    "- F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.723\n"
     ]
    }
   ],
   "source": [
    "# Porcentaje de muestras predichas correctamente\n",
    "print(\"Accuracy\", round(accuracy_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precission 0.729\n"
     ]
    }
   ],
   "source": [
    "# De los predichos, porcentaje de eventos positivos predichos que son realmente positivos \n",
    "print(\"Precission\", round(precision_score(y_test, y_pred, average = 'weighted'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.723\n"
     ]
    }
   ],
   "source": [
    "# Porcentaje de eventos positivos predichos sobre los positivos reales\n",
    "print(\"Recall\", round(recall_score(y_test, y_pred, average = 'weighted'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score 0.72\n"
     ]
    }
   ],
   "source": [
    "# Recall + Precission\n",
    "print(\"F1_score\", round(f1_score(y_test, y_pred, average = 'weighted'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training several models and explores the metrics for each of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DecisionTreeClassifier\n",
    "- SVC\n",
    "- RandomForestClassifier\n",
    "- AdaBoostClassifier\n",
    "- DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.973\n",
      "Precission 0.973\n",
      "Recall 0.973\n",
      "F1_score 0.973\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree classifer object\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "decision_tree = dt.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Precission\", round(precision_score(y_test, y_pred, average = 'weighted'), 3))\n",
    "print(\"Recall\", round(recall_score(y_test, y_pred, average = 'weighted'), 3))\n",
    "print(\"F1_score\", round(f1_score(y_test, y_pred, average = 'weighted'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.683\n",
      "Precission 0.707\n",
      "Recall 0.683\n",
      "F1_score 0.647\n"
     ]
    }
   ],
   "source": [
    "svc_ = SVC()\n",
    "svc = svc_.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Precission\", round(precision_score(y_test, y_pred, average = 'weighted'), 3))\n",
    "print(\"Recall\", round(recall_score(y_test, y_pred, average = 'weighted'), 3))\n",
    "print(\"F1_score\", round(f1_score(y_test, y_pred, average = 'weighted'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.987\n",
      "Precission 0.987\n",
      "Recall 0.987\n",
      "F1_score 0.987\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "random_forest = rf.fit(X_train,y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Precission\", round(precision_score(y_test, y_pred, average = 'weighted'), 3))\n",
    "print(\"Recall\", round(recall_score(y_test, y_pred, average = 'weighted'), 3))\n",
    "print(\"F1_score\", round(f1_score(y_test, y_pred, average = 'weighted'), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.49\n",
      "Precission 0.295\n",
      "Recall 0.49\n",
      "F1_score 0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/victor/opt/miniconda3/envs/ironhack/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier()\n",
    "ada_boost = ab.fit(X_train,y_train)\n",
    "y_pred = ada_boost.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\", round(accuracy_score(y_test, y_pred), 3))\n",
    "print(\"Precission\", round(precision_score(y_test, y_pred, average = 'weighted'), 3))\n",
    "print(\"Recall\", round(recall_score(y_test, y_pred, average = 'weighted'), 3))\n",
    "print(\"F1_score\", round(f1_score(y_test, y_pred, average = 'weighted'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deberíamos escoger el Random Forest Classifier, ya que su predicción de positivos es mejor, tanto sobre todos los predichos como sobre los positivos reales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hope-you-enjoy](https://imgs.xkcd.com/comics/machine_learning.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
